---
title: The little sample that could
author: Matthew Brett
date: 24 April 2025
format: revealjs
---

## A confounded statistician

It is 2009, and I'm a statistician working in North Carolina.

I want to estimate the average birth weight for babies born in the state.

The state has [records of the birth weights for all babies born in
2008](https://github.com/odsti/datasets/tree/main/birth_weights), but for
privacy reasons, it will not release them.

They have given me a random sample of 50 birth weights.

## The lonely sample

```{r}
#| tags: [remove_input]
source('../confidence_plots.R')
```

```{r}
#| tags: [remove_input]
bw_sample_vals
```

## A lonely distribution

```{r}
#| tags: [remove_input]
plot_bw(bw_sample) + labs(title = 'Our sample') + samp_ylims
```

## So where's the problem?

I have my sample mean.

But I want to know the mean of the *population* (all births in the state).

I don't have the population values.

We now come to the crucial problem in statistics: given my *sample*, what can I say about the *population*?

Here: given my sample, what can I say about the population mean?

## Sampling variation

We have to think about the process by which our sample came about.

It was a random sample from all the births.

Because it was a random sample, the mean of the sample is also somewhat
random.

## The curtain pulls back

In 2010, I will get all the state's data.  This is the *population* from which the sample is drawn.   It will turn out that it looks like this:

```{r}
#| tags: [remove_input]
pop_p <- plot_bw(bw_pop) + labs(
    title = 'All NC birth weights',
    subtitle = '(Population)')
pop_p
```

## Why is my sample mean (a little bit) random?

Let's stay in 2010, and draw four more samples.

```{r}
#| tags: [remove_input]
# From: <https://wilkelab.org/cowplot/articles/shared_legends.html>
p_samps <- plot_grid(
    plotlist = plots,
    align = 'vh',
    labels = sapply(1:n_samples, function(i) glue('S{i + 1}')),
    nrow = 1
)
p_samps
```

## Building the sampling distribution

Notice that, each time I draw a new sample, I get a slightly different sample
mean.

```{r}
#| tags: [remove_input]
p_whole <- plot_grid(
    pop_p + labs(title=NULL) + theme(legend.position='none'),
    plot_grid(plotlist = plots, align = 'vh', nrow = 1),
    plot_grid(plotlist = samp_dists, align = 'vh', nrow = 1),
    ncol = 1)
p_whole
```

## With 10,000 samples ...

```{r}
#| tags: [remove_input]
full_samp_breaks <- seq(2.9, 3.6, samp_bin_width)
m_s_d <- mean(samp_dist_vals)
x_label <- glue('Sample means: mean {round(m_s_d, 2)}')
p_s_dist <- (
    ggplot(samp_dist, aes(sample_mean))
    + geom_histogram(breaks = full_samp_breaks)
    + geom_vline(aes(xintercept=m_s_d),
                 linewidth=1,
                 linetype='dashed')
    + labs(x = x_label)
    + theme(legend.position='none')
    + labs(title='Sampling distribution of mean')
)
p_s_dist
```

## Cartoon of sampling distribution

```{r}
#| tags: [remove_input]
p <- (ggplot(samp_dist, aes(sample_mean))
      + geom_histogram(breaks = full_samp_breaks, alpha=0.5)
      + geom_line(data = kde_df, aes(x = x, y = y),
                  linewidth=2)
      )
p
```

## Estimating the sampling distribution

It turns out we can get a decent estimate of the sampling distribution, from the distribution of the sample itself (ask me how!).

```{r}
#| tags: [remove_input]
plot_bw(bw_sample) + labs(title = 'Our sample') + samp_ylims
```

However, this estimate does not tell us more about the *population mean*, only the size and shape of the sampling distribution.

## Sampling distribution estimate

```{r}
#| tags: [remove_input]
rm_x_ticks <- theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank())
(ggplot(samp_dist, aes(sample_mean))
      + geom_area(data = kde_df, aes(x = x, y = y), alpha=0.5)
      + rm_x_ticks
      )
```

## {background-video="moving_dist.mp4" background-video-loop="true" background-size="contain"}

## What can we do with this?

With the size and shape, we can estimate where the 2.5% and 97.5% tails are on
the distribution, relative to the mean.

```{r}
#| tags: [remove_input]

plot_mdist_tails <- function(df, offset=0, tails='both') {
    p <- plot_ssamp_dist(df, offset)
    lt <- data.table::copy(lower_tail)
    lt$x <- lt$x + offset
    ut <- data.table::copy(upper_tail)
    ut$x <- ut$x + offset
    if (tails %in% c('both', 'left')) {
        p <- p + geom_area(data = lt, aes(x=x, y=y), fill="red")
    }
    if (tails %in% c('both', 'right')) {
        p <- p + geom_area(data = ut, aes(x=x, y=y), fill="red")
    }
    p
}


plot_with_arrows <- function(df, offset=0, arrows='both') {
    p <- plot_mdist_tails(df, offset, tails=arrows)
    mid_upper <- m_samp_dist - upper_diff / 2
    mid_lower <- m_samp_dist - lower_diff / 2
    e <- 0.01
    if (arrows %in% c('both', 'left')) {
        p <- (p
        + geom_segment(aes(x = lo_025_th + e + offset,
                           y = 30,
                           xend = m_samp_dist - e + offset,
                           yend = 30),
                       arrow = arrow(length = unit(0.5, "cm")))
        + annotate("text", x = mid_upper + offset,
                   y = 50,
                   label = glue('{round(upper_diff, 2)}'))
        )
    }
    if (arrows == 'both' | arrows == 'right') {
        p <- (p
        + geom_segment(aes(x = hi_975_th - e + offset,
                           y = 30,
                           xend = m_samp_dist + e + offset,
                           yend = 30),
                       arrow = arrow(length = unit(0.5, "cm")))
        + annotate("text",
                   x = mid_lower + offset,
                   y = 50,
                   label = glue('{round(lower_diff, 2)}'))
        )
    }
    p
}

plot_with_arrows(kde_df) + rm_x_ticks
```

## Confidence intervals

We know our sample mean came from the sampling distribution of the mean.

But we don't know where the population mean is.

Assume we were unlucky, and our sample mean is low, and at the 2.5 percentile.

## How high could the population mean be?

Assume our sample mean is at the 2.5 percentile of the sampling distribution.

Superimpose the sampling distribution estimate.

## Sample mean at 2.5 percentile

```{r}
sm_label = glue('Sample mean = {round(sample_mean, 2)}')
offset = sample_mean + upper_diff - pop_mean
(plot_with_arrows(kde_df, offset, arrows='left')
 + labs(x = '')
 + geom_vline(aes(xintercept=sample_mean),
              linewidth=1,
              linetype='dashed')
 + annotate("text",
            x = sample_mean - 0.11,
            y = 400,
            label = sm_label)
 )
```

```{r}
#| echo: false
r_sm <- round(sample_mean, 2)
r_ud <- round(upper_diff, 2)
r_ld <- round(lower_diff, 2)
```

Barely likely unlucky case (sample mean low), population mean is `{r} r_sm`
+ `{r} r_ud` = `{r} r_sm + r_ud`.

## How low could the population mean be?

Assume our sample mean is at the 97.5 percentile of the sampling distribution.

Superimpose the sampling distribution estimate.

## Sample mean at 97.5 percentile

```{r}
offset = sample_mean + lower_diff - pop_mean
(plot_with_arrows(kde_df, offset, arrow='right')
 + labs(x = '')
 + geom_vline(aes(xintercept=sample_mean),
              linewidth=1,
              linetype='dashed')
 + annotate("text",
            x = sample_mean + 0.11,
            y = 400,
            label = sm_label)
 )
```

Barely likely unlucky case (sample mean high), population mean is `{r} r_sm`
- `{r} -r_ld` = `{r} r_sm + r_ld`.

## Confidence intervals

The me of 2009, before I saw the population data, can say:

> Given my sample, the 95% confidence intervals for the population mean are
> `{r} r_sm + r_ld` to `{r} r_sm + r_ud`.
